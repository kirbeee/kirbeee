---
id: Model Merging
title: Model Merging
last_update:
   date: 2025-08-06
   author: Kirbee
---
## Diagram

### Is this really working? Neural Network Can Add?
- Paper: [Editing Models with Task Arithmetic](https://arxiv.org/abs/2212.04089)
- paper: [Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages](https://arxiv.org/abs/2310.04799)

## learning via addition
- 通常調整相加比例會有更好的結果
- paper: [Model Stock: All we need is just a few fine-tuned models](https://arxiv.org/abs/2403.19522)

### Example

[//]: # (- TODO: add img)
- paper: [DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging](https://arxiv.org/abs/2407.01470)

[//]: # (TODO: add IMG)
- paper: [Transferring Textual Preferences to Vision-Language Understanding through Model Merging](https://arxiv.org/pdf/2502.13487)

## Forgetting via negation (Machine Unlearning)
- example: [台灣化LLM的實踐經驗分享 3 |Chat Vector—神奇的 LLM 積木](https://aqweteddy.medium.com/台灣化-llm-的實踐經驗分享-3-chat-vector-神奇的-llm-積木-be5aadd5c1c0)

## Task analogies

